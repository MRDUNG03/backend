import os
import sys
import pickle
import numpy as np
import pandas as pd
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# In tiáº¿ng Viá»‡t trÃªn Windows
sys.stdout.reconfigure(encoding="utf-8")

# ============== Cáº¤U HÃŒNH ==============
# 1) Model SVM Ä‘Ã£ train vÃ  lÆ°u dáº¡ng .pkl
MODEL_PKL_PATH = r"D:\SVM\svm_model_from_raw.pkl"

# 2) File Ä‘áº·c trÆ°ng 4 lá»›p dÃ¹ng Ä‘á»ƒ train (Ä‘á»ƒ láº¥y Ä‘Ãºng danh sÃ¡ch feature)
FEATURE_CSV_PATH = r"D:\Data\features_4class.csv"

# 3) File RAW cáº§n test (má»—i láº§n Ä‘á»•i 1 file)
#    VÃ­ dá»¥:
#    - Electrical:   r"D:\Data\data_electrical_1\Electrical_clean.csv"
#    - Overheating:  r"D:\Data\data_overheating_1\Overheating1.csv"
#    - Misalignment: r"D:\Data\data_misalignment_1\Misalignment_clean.csv"
#    - Normal:       r"D:\Data\data_normal_1\NORMAL_1.csv"
TEST_RAW_CSV     = r"D:\SVM\Misalignment_clean.csv"
# Sá»‘ cá»­a sá»• chia má»—i file
N_SEGMENTS       = 10
# ======================================


def load_feature_cols():
    """Láº¥y danh sÃ¡ch feature Ä‘Ã£ dÃ¹ng Ä‘á»ƒ train tá»« features_4class.csv"""
    if not os.path.exists(FEATURE_CSV_PATH):
        raise FileNotFoundError(f"âŒ KhÃ´ng tÃ¬m tháº¥y file: {FEATURE_CSV_PATH}")

    df = pd.read_csv(FEATURE_CSV_PATH)

    # bá» cÃ¡c cá»™t khÃ´ng pháº£i feature (giá»‘ng khi train)
    drop_cols = ["label", "window_index", "start_time"]
    X = df.drop(columns=drop_cols, errors="ignore")

    # chá»‰ giá»¯ cá»™t sá»‘
    X = X.select_dtypes(include=[np.number])

    feature_cols = X.columns.tolist()
    print("ğŸ“‹ Feature dÃ¹ng Ä‘á»ƒ train (Ä‘Ãºng thá»© tá»±):")
    print(feature_cols, "\n")
    return feature_cols


def extract_features_from_raw(raw_csv_path, feature_cols, n_segments=10):
    """
    Äá»c file raw (ax, ay, az, current, voltage, temp, label),
    chia thÃ nh n_segments cá»­a sá»• Ä‘á»u nhau,
    trÃ­ch:
      Mean/RMS/STD/Peak cho ax, ay, az, current, voltage
      Mean_temp
    """
    if not os.path.exists(raw_csv_path):
        raise FileNotFoundError(f"âŒ KhÃ´ng tÃ¬m tháº¥y file raw: {raw_csv_path}")

    df = pd.read_csv(raw_csv_path)
    print(f"ğŸ“¥ ÄÃ£ Ä‘á»c file: {raw_csv_path}")
    print("   CÃ¡c cá»™t:", df.columns.tolist())

    required_cols = ["ax", "ay", "az", "current", "voltage", "temp"]
    for c in required_cols:
        if c not in df.columns:
            raise ValueError(f"âŒ File {raw_csv_path} thiáº¿u cá»™t '{c}'.")

    n_samples = len(df)
    n_per_seg = n_samples // n_segments
    n_cut = n_per_seg * n_segments
    df = df.iloc[:n_cut].reset_index(drop=True)

    print(f"   Tá»•ng máº«u: {n_samples} â†’ dÃ¹ng {n_cut}, má»—i cá»­a sá»•: {n_per_seg} máº«u")

    # Láº¥y nhÃ£n tháº­t náº¿u cÃ³ cá»™t label, cÃ²n khÃ´ng thÃ¬ cho Unknown
    if "label" in df.columns:
        true_label = str(df["label"].iloc[0])
    else:
        true_label = "Unknown"

    rows = []

    def feat_1d(x):
        x = x.astype(float).values
        return dict(
            mean=float(np.mean(x)),
            rms=float(np.sqrt(np.mean(x**2))),
            std=float(np.std(x)),
            peak=float(np.max(np.abs(x))),
        )

    for i in range(n_segments):
        start = i * n_per_seg
        end   = (i + 1) * n_per_seg
        seg   = df.iloc[start:end]

        f_ax  = feat_1d(seg["ax"])
        f_ay  = feat_1d(seg["ay"])
        f_az  = feat_1d(seg["az"])
        f_cur = feat_1d(seg["current"])
        f_vol = feat_1d(seg["voltage"])
        mean_temp = float(np.mean(seg["temp"].astype(float).values))

        row = {
            "window_index": i,  # index tá»« 0
            "Mean_ax": f_ax["mean"],
            "RMS_ax":  f_ax["rms"],
            "STD_ax":  f_ax["std"],
            "Peak_ax": f_ax["peak"],

            "Mean_ay": f_ay["mean"],
            "RMS_ay":  f_ay["rms"],
            "STD_ay":  f_ay["std"],
            "Peak_ay": f_ay["peak"],

            "Mean_az": f_az["mean"],
            "RMS_az":  f_az["rms"],
            "STD_az":  f_az["std"],
            "Peak_az": f_az["peak"],

            "Mean_current": f_cur["mean"],
            "RMS_current":  f_cur["rms"],
            "STD_current":  f_cur["std"],
            "Peak_current": f_cur["peak"],

            "Mean_voltage": f_vol["mean"],
            "RMS_voltage":  f_vol["rms"],
            "STD_voltage":  f_vol["std"],
            "Peak_voltage": f_vol["peak"],

            "Mean_temp": mean_temp,
            "label": true_label,
        }

        rows.append(row)

    df_feat = pd.DataFrame(rows)

    # Äáº£m báº£o cÃ³ Ä‘á»§ cá»™t feature, Ä‘Ãºng thá»© tá»±
    for c in feature_cols:
        if c not in df_feat.columns:
            df_feat[c] = 0.0

    df_feat = df_feat[["window_index"] + feature_cols + ["label"]]
    return df_feat


def main():
    # 1. Load model
    if not os.path.exists(MODEL_PKL_PATH):
        raise FileNotFoundError(f"âŒ KhÃ´ng tÃ¬m tháº¥y model .pkl: {MODEL_PKL_PATH}")

    print(f"âœ… Äang load model tá»«: {MODEL_PKL_PATH}")
    with open(MODEL_PKL_PATH, "rb") as f:
        model = pickle.load(f)
    print("âœ… ÄÃ£ load model.\n")

    # 2. Láº¥y danh sÃ¡ch feature
    feature_cols = load_feature_cols()

    # 3. TrÃ­ch Ä‘áº·c trÆ°ng tá»« file RAW
    print(f"ğŸ” Äang trÃ­ch Ä‘áº·c trÆ°ng tá»« file: {TEST_RAW_CSV}")
    df_feat = extract_features_from_raw(TEST_RAW_CSV, feature_cols, n_segments=N_SEGMENTS)

    print("\nğŸ“Š 5 dÃ²ng Ä‘áº§u Ä‘áº·c trÆ°ng:")
    print(df_feat.head())
    print("\nKÃ­ch thÆ°á»›c Ä‘áº·c trÆ°ng:", df_feat.shape, "\n")

    X_test = df_feat[feature_cols]
    y_true = df_feat["label"]

    # 4. Dá»± Ä‘oÃ¡n
    y_pred = model.predict(X_test)

    print("=== Káº¾T QUáº¢ Tá»ªNG Cá»¬A Sá»” ===")
    for i in range(len(X_test)):
        win = int(df_feat.loc[i, "window_index"])
        print(f"Window {win:03d}: thá»±c táº¿ = {y_true.iloc[i]:12s} | dá»± Ä‘oÃ¡n = {y_pred[i]:12s}")
    print("================================\n")

    # 5. Äá»™ chÃ­nh xÃ¡c trÃªn riÃªng file nÃ y
    acc = accuracy_score(y_true, y_pred) * 100.0
    print(f"ğŸ¯ Äá»™ chÃ­nh xÃ¡c (accuracy) cho file nÃ y: {acc:.2f}%\n")

    print("=== Classification report ===")
    print(classification_report(y_true, y_pred))

    labels_sorted = sorted(y_true.unique())
    cm = confusion_matrix(y_true, y_pred, labels=labels_sorted)
    print("=== Confusion matrix ===")
    print("Labels:", labels_sorted)
    print(cm)

    # 6. XÃ¡c suáº¥t tá»«ng lá»›p (náº¿u model há»— trá»£)
    if hasattr(model, "predict_proba"):
        proba = model.predict_proba(X_test)   # (n_windows, n_classes)
        classes = model.classes_

        # Trung bÃ¬nh % trÃªn toÃ n bá»™ cá»­a sá»• â†’ giá»‘ng kiá»ƒu báº¡n muá»‘n
        mean_proba = proba.mean(axis=0)
        print("\nğŸ” XÃ¡c suáº¥t tá»«ng lá»›p (trung bÃ¬nh cho Cáº¢ FILE):")
        order = np.argsort(mean_proba)[::-1]
        for idx in order:
            cls = classes[idx]
            pct = mean_proba[idx] * 100
            print(f"- {cls}: {pct:.2f}%")

        # Náº¿u muá»‘n xem vÃ­ dá»¥ 3 cá»­a sá»• Ä‘áº§u:
        print("\nğŸ” VÃ­ dá»¥ xÃ¡c suáº¥t 3 cá»­a sá»• Ä‘áº§u:")
        for i in range(min(3, len(X_test))):
            print(f"  Window {int(df_feat.loc[i, 'window_index']):03d}:")
            p = proba[i]
            order_i = np.argsort(p)[::-1]
            for idx in order_i:
                cls = classes[idx]
                pct = p[idx] * 100
                print(f"    - {cls}: {pct:.2f}%")
    else:
        print("\nâš ï¸ Model khÃ´ng há»— trá»£ predict_proba (cáº§n probability=True khi train).")


if __name__ == "__main__":
    main()
